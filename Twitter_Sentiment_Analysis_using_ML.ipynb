{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6e+gxy8WtVa/31EcjkKsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyadarshi04/Sentiment-analysis-with-tweets/blob/master/Twitter_Sentiment_Analysis_using_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system('pip install kaggle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w_9eRLI2PP_",
        "outputId": "74e568aa-a9e2-4426-9ef2-d24b9b83960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your kaggle.json,file\n"
      ],
      "metadata": {
        "id": "v2I8L9lB4xm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cnfiguring the path of kaggle.json.file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qCS74jAs5Ia2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Twitter Sentiment dataset"
      ],
      "metadata": {
        "id": "cZpZxvtL6RqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVbFThLW6h0D",
        "outputId": "c3cdd5c9-b7f4-4c5c-f646-7106e5f2b3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/cli.py\", line 70, in main\n",
            "    out = args.func(**command_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1493, in dataset_download_cli\n",
            "    self.dataset_download_files(dataset,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1447, in dataset_download_files\n",
            "    self.download_file(response, outfile, quiet, not force)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1834, in download_file\n",
            "    size = int(response.headers['Content-Length'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/_collections.py\", line 258, in __getitem__\n",
            "    val = self._container[key.lower()]\n",
            "KeyError: 'content-length'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2eNyZl_O7bx",
        "outputId": "33267ef8-7ec9-4001-d462-9f2a750686fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qlXfTcLPJUo",
        "outputId": "c96c3aa3-796e-465b-ed5a-93548023b896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade zipfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOMjRbXlM2Nl",
        "outputId": "63476f44-10ca-49b3-a1b6-99767ae2c091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for zipfile\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the compressed dataset\n",
        "from zipfile import Zipfile\n",
        "df = !kaggle datasets download -d kazanova/sentiment140\n",
        "with zipfile.Zipfile(df[0], 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "iTzgYQQFKg4v",
        "outputId": "85d8cdc7-b8ab-488f-a5b8-b7815e2575ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Zipfile' from 'zipfile' (/usr/lib/python3.10/zipfile.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dd522e5e4e30>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#extracting the compressed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle datasets download -d kazanova/sentiment140'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Zipfile' from 'zipfile' (/usr/lib/python3.10/zipfile.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "2nqSMHNvQ6RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "eATCoWqaQo3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "wq2xdsAATtID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the stopwords in English\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "rpPWt5XCT9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Processing"
      ],
      "metadata": {
        "id": "hv05lGseU5H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data from csv file to pandas dataframe\n",
        "twitter_data =pd.read_csv('/content/training.1600000.processed.noemoticon.csv' ,encoding ='ISO-8859-1')"
      ],
      "metadata": {
        "id": "uwjpj0TCU-u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkin gthe number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "yjJPSU1qWSBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the first 5 rows of the dataframe\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "o2X9ky8LW2tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naming the columns and reading  the dataset again\n",
        "\n",
        "column_names =['target' ,'id', 'date','flag','user','text']\n",
        "twitter_data =pd.read_csv('/content/training.1600000.processed.noemoticon.csv' , names=column_names, encoding ='ISO-8859-1')"
      ],
      "metadata": {
        "id": "nO0BXpO2XdzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkin gthe number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "id": "Pg9oGmMtZd_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the first 5 rows of the dataframe\n",
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "0RelecLiZwj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of missing values in the dataset\n",
        "twitter_data.isnull().sum()"
      ],
      "metadata": {
        "id": "Y8c3pBP9aFv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of the target column\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "5GY1o3k5bXQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the target \"4\" to \"1\""
      ],
      "metadata": {
        "id": "C51Y9WVmceGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.replace({4:1}, inplace=True)"
      ],
      "metadata": {
        "id": "sqIoDxWKcOIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of the target column\n",
        "twitter_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "TnRpdNHhdvk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0->Negative Tweet\n",
        "\n",
        "1->Positive Tweet"
      ],
      "metadata": {
        "id": "jxkq_Azsep6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "0J-ZA0rbfE7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming is the process of reducing a word to its Root word"
      ],
      "metadata": {
        "id": "MixJcf0EfXQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "example :actor,actress,acting =act"
      ],
      "metadata": {
        "id": "-GujHNeHfyDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem =PorterStemmer()"
      ],
      "metadata": {
        "id": "an_76-Xre9sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "\n",
        "  stemmed_content =re.sub('[^a-zA-Z]','',content)\n",
        "  stemmed_content =stemmed_content.lower()\n",
        "  stemmed_content =stemmed_content.split()\n",
        "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "\n",
        "  return stemmed_content"
      ],
      "metadata": {
        "id": "Pg7NL45Rgepy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)"
      ],
      "metadata": {
        "id": "Dpmpm1Ork82y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "jglwHg44k8zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['stemmed_content'])"
      ],
      "metadata": {
        "id": "X845AhY5ovPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(twitter_data['target'])"
      ],
      "metadata": {
        "id": "8abfZRrJpKNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and label\n",
        "X =twitter_data['stemmed_content'].values\n",
        "Y =twitter_data['target'].values"
      ],
      "metadata": {
        "id": "e1Qrri8FppXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "MaxXkgt8qXrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "0M3S-WLsqqwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data to training data and test data"
      ],
      "metadata": {
        "id": "ZHq7luYEq04S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test,Y_train,Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
      ],
      "metadata": {
        "id": "Y4FMYlcpquwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "id": "AzrBsXM-tFu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "QCR983ykthSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "vkv5QF4Qtq_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "FWIW0hlhv0wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "KzuVev8sv68c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the textual data to numerical data\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train =vectorizer.fit_transform(X_train)\n",
        "X_test =vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "4V3L-Sk4t7sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "Ff8xJQOuwQKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "ARSxuGhmwXvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Machine Learning Model"
      ],
      "metadata": {
        "id": "lgCHSUKowvnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "NGBd1O6Nw_zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ],
      "metadata": {
        "id": "AIt3KSRixNh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "zzEUEOipxsgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOdel Evaluation"
      ],
      "metadata": {
        "id": "4IJXL2nuySQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score"
      ],
      "metadata": {
        "id": "VAMlzl30yd5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "1bOKIbpV0bQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prediction = model.predict(X_train)"
      ],
      "metadata": {
        "id": "gZYNtxof0owj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
      ],
      "metadata": {
        "id": "CIPhW3tRyY5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "\n",
        "print(\"Accuracy score on the training data:\", training_data_accuracy)"
      ],
      "metadata": {
        "id": "2wtvTCRj2CEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "TBhj3IR_0l_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "WILYNUnJ0ovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score on the test data\n",
        "# Import the required modules\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict the labels for the test data\n",
        "X_test_prediction = model.predict(X_test.values)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(f\"Accuracy score on the test data: {test_data_accuracy}\")"
      ],
      "metadata": {
        "id": "XcMlQwXk0AUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}